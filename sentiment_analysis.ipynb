{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the code that I am using!\n",
    "citation: \n",
    "Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n",
    "https://github.com/cjhutto/vaderSentiment/blob/master/README.rst\n",
    "https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vaderSentiment.py\n",
    "https://github.com/cjhutto/vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example that I copied and modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER is smart, handsome, and funny.----------------------------- {'neg': 0.0, 'neu': 0.254, 'pos': 0.746, 'compound': 0.8316}\n",
      "VADER is smart, handsome, and funny!----------------------------- {'neg': 0.0, 'neu': 0.248, 'pos': 0.752, 'compound': 0.8439}\n",
      "VADER is very smart, handsome, and funny.------------------------ {'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.8545}\n",
      "VADER is VERY SMART, handsome, and FUNNY.------------------------ {'neg': 0.0, 'neu': 0.246, 'pos': 0.754, 'compound': 0.9227}\n",
      "VADER is VERY SMART, handsome, and FUNNY!!!---------------------- {'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'compound': 0.9342}\n",
      "VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!--------- {'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.9469}\n",
      "VADER is not smart, handsome, nor funny.------------------------- {'neg': 0.646, 'neu': 0.354, 'pos': 0.0, 'compound': -0.7424}\n",
      "The book was good.----------------------------------------------- {'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "At least it isn't a horrible book.------------------------------- {'neg': 0.0, 'neu': 0.637, 'pos': 0.363, 'compound': 0.431}\n",
      "The book was only kind of good.---------------------------------- {'neg': 0.0, 'neu': 0.697, 'pos': 0.303, 'compound': 0.3832}\n",
      "The plot was good, but the characters are uncompelling and the dialog is not great. {'neg': 0.327, 'neu': 0.579, 'pos': 0.094, 'compound': -0.7042}\n",
      "Today SUX!------------------------------------------------------- {'neg': 0.779, 'neu': 0.221, 'pos': 0.0, 'compound': -0.5461}\n",
      "Today only kinda sux! But I'll get by, lol----------------------- {'neg': 0.127, 'neu': 0.556, 'pos': 0.317, 'compound': 0.5249}\n",
      "Make sure you :) or :D today!------------------------------------ {'neg': 0.0, 'neu': 0.294, 'pos': 0.706, 'compound': 0.8633}\n",
      "Catch utf-8 emoji such as such as üíò and üíã and üòÅ------------------ {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'compound': 0.7003}\n",
      "Not bad at all--------------------------------------------------- {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.431}\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    #note: depending on how you installed (e.g., using source code download versus pip install), you may need to import like this:\n",
    "    #from vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# --- examples -------\n",
    "sentences = [\"VADER is smart, handsome, and funny.\",  # positive sentence example\n",
    "             \"VADER is smart, handsome, and funny!\",  # punctuation emphasis handled correctly (sentiment intensity adjusted)\n",
    "             \"VADER is very smart, handsome, and funny.\", # booster words handled correctly (sentiment intensity adjusted)\n",
    "             \"VADER is VERY SMART, handsome, and FUNNY.\",  # emphasis for ALLCAPS handled\n",
    "             \"VADER is VERY SMART, handsome, and FUNNY!!!\", # combination of signals - VADER appropriately adjusts intensity\n",
    "             \"VADER is VERY SMART, uber handsome, and FRIGGIN FUNNY!!!\", # booster words & punctuation make this close to ceiling for score\n",
    "             \"VADER is not smart, handsome, nor funny.\",  # negation sentence example\n",
    "             \"The book was good.\",  # positive sentence\n",
    "             \"At least it isn't a horrible book.\",  # negated negative sentence with contraction\n",
    "             \"The book was only kind of good.\", # qualified positive sentence is handled correctly (intensity adjusted)\n",
    "             \"The plot was good, but the characters are uncompelling and the dialog is not great.\", # mixed negation sentence\n",
    "             \"Today SUX!\",  # negative slang with capitalization emphasis\n",
    "             \"Today only kinda sux! But I'll get by, lol\", # mixed sentiment example with slang and constrastive conjunction \"but\"\n",
    "             \"Make sure you :) or :D today!\",  # emoticons handled\n",
    "             \"Catch utf-8 emoji such as such as üíò and üíã and üòÅ\",  # emojis handled\n",
    "             \"Not bad at all\"  # Capitalized negation\n",
    "             ]\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    print(\"{:-<65} {}\".format(sentence, str(vs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The library staff were incredibly helpful in answering my questions! {'neg': 0.0, 'neu': 0.727, 'pos': 0.273, 'compound': 0.5244}\n",
      "I love our library staff!---------------------------------------- {'neg': 0.0, 'neu': 0.4, 'pos': 0.6, 'compound': 0.6696}\n",
      "I wish that the library staff had listened more to the question that I asked. {'neg': 0.0, 'neu': 0.816, 'pos': 0.184, 'compound': 0.4019}\n",
      "I had to wait a long time to be helped.-------------------------- {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "I found the library web presence confusing for my research.------ {'neg': 0.192, 'neu': 0.808, 'pos': 0.0, 'compound': -0.2263}\n",
      "I was upset that I had to wait a couple days for the library to get back to me about my question. {'neg': 0.126, 'neu': 0.874, 'pos': 0.0, 'compound': -0.3818}\n",
      " \n",
      "Positive values: \n",
      "[0.273, 0.6, 0.184, 0.0, 0.0, 0.0]\n",
      "Average positive:\n",
      "0.17616666666666667\n",
      "\n",
      "Negative values: \n",
      "[0.0, 0.0, 0.0, 0.0, 0.192, 0.126]\n",
      "Average negative:\n",
      "0.053\n",
      "\n",
      "Neutral values: \n",
      "[0.727, 0.4, 0.816, 1.0, 0.808, 0.874]\n",
      "Average neutral:\n",
      "0.7708333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "   \n",
    "from xlrd import open_workbook\n",
    "\n",
    "book = open_workbook(\"fakecomments.xlsx\")\n",
    "sheet = book.sheet_by_index(0) #If your data is on sheet 1\n",
    "\n",
    "sentences = []\n",
    "compoundlist = []\n",
    "poslist = []\n",
    "neglist = []\n",
    "neulist = []\n",
    "\n",
    "\n",
    "for row in range(0, 6): #start from 1, to leave out row 0\n",
    "    sentences.append(sheet.cell(row, 0).value) \n",
    "    \n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    print(\"{:-<65} {}\".format(sentence, str(vs))) \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    pos = sid.polarity_scores(sentence)['pos']\n",
    "    poslist.append(pos)\n",
    "    neg = sid.polarity_scores(sentence)['neg']\n",
    "    neglist.append(neg)\n",
    "    neu = sid.polarity_scores(sentence)['neu']\n",
    "    neulist.append(neu)\n",
    "    compoundlist = sid.polarity_scores(sentence)['compound']\n",
    "    #compoundlist.append(str(compound))\n",
    "    \n",
    "print(\" \")\n",
    "print(\"Positive values: \")\n",
    "print(poslist)\n",
    "print(\"Average positive:\")\n",
    "print(sum(poslist) / len(poslist))\n",
    "\n",
    "print(\"\\nNegative values: \")\n",
    "print(neglist)\n",
    "print(\"Average negative:\")\n",
    "print(sum(neglist) / len(neglist))\n",
    "\n",
    "print(\"\\nNeutral values: \")\n",
    "print(neulist)\n",
    "print(\"Average neutral:\")\n",
    "print(sum(neulist) / len(neulist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# second cite:\n",
    "Learned how to get average of data above from this conversation string: (William Van Onsem)\n",
    "https://stackoverflow.com/questions/42650881/how-to-get-the-positive-score-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Positive values: \n",
      "[0.273, 0.6, 0.184, 0.0, 0.0, 0.0]\n",
      "Average positive:\n",
      "0.17616666666666667\n",
      "\n",
      "Negative values: \n",
      "[0.0, 0.0, 0.0, 0.0, 0.192, 0.126]\n",
      "Average negative:\n",
      "0.053\n",
      "\n",
      "Neutral values: \n",
      "[0.727, 0.4, 0.816, 1.0, 0.808, 0.874]\n",
      "Average neutral:\n",
      "0.7708333333333334\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "   \n",
    "from xlrd import open_workbook\n",
    "\n",
    "book = open_workbook(\"570comments.xlsx\")\n",
    "sheet = book.sheet_by_index(0) #If your data is on sheet 1\n",
    "\n",
    "sentences = []\n",
    "compoundlist = []\n",
    "poslist = []\n",
    "neglist = []\n",
    "neulist = []\n",
    "\n",
    "\n",
    "for row in range(0, 1173): #start from 1, to leave out row 0\n",
    "    sentences.append(sheet.cell(row, 0).value) \n",
    "    \n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    (\"{:-<65} {}\".format(sentence, str(vs))) \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    pos = sid.polarity_scores(sentence)['pos']\n",
    "    poslist.append(pos)\n",
    "    neg = sid.polarity_scores(sentence)['neg']\n",
    "    neglist.append(neg)\n",
    "    neu = sid.polarity_scores(sentence)['neu']\n",
    "    neulist.append(neu)\n",
    "    compoundlist = sid.polarity_scores(sentence)['compound']\n",
    "    #compoundlist.append(str(compound))\n",
    "    \n",
    "print(\" \")\n",
    "print(\"Positive values: \")\n",
    "print(poslist)\n",
    "print(\"Average positive:\")\n",
    "print(sum(poslist) / len(poslist))\n",
    "\n",
    "print(\"\\nNegative values: \")\n",
    "print(neglist)\n",
    "print(\"Average negative:\")\n",
    "print(sum(neglist) / len(neglist))\n",
    "\n",
    "print(\"\\nNeutral values: \")\n",
    "print(neulist)\n",
    "print(\"Average neutral:\")\n",
    "print(sum(neulist) / len(neulist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
